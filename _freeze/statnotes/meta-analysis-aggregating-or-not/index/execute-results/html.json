{
  "hash": "6201913530f3b3e2978ba289b6df6119",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Aggregating or not?\"\ndate: last-modified\ncategories: [meta-analysis]\n---\n\n\n# Aggregating or not?\n\nWith complex data structures in meta-analysis sometimes we want to aggregate effect size to simplify the analysis. As reported by James Pustejovsky, [\"sometimes, aggregating effect sizes is fine\"](https://www.jepusto.com/sometimes-aggregating-effect-sizes-is-fine/). The blog post show formally why aggregating or not, in specific condition, brings the exactly same results with some additional pros in terms of computational speed. Crucially, this is true **only in specific conditions**.\n\n> In this post Iâ€™ll highlight one such circumstance, where aggregating effect size estimates is not only reasonable but leads to exactly the same results as a multivariate model. This occurs when two conditions are met:\n- We are not interested in within-study heterogeneity of effects\n- Any predictors included in the model vary between studies but not within a given study (i.e., effect sizes from the same study all have the same values of the predictors).\nIn short, if all we care about is understanding between-study variation in effect sizes, then it is fine to aggregate them up to the study level.\n\nThe example refers to a situation where I have multiple effects collected on the same pool of subjects nested within papers. Thus if I have predictors at the level of the effect or I'm interested in modelling variability within papers, **aggregating is not good**.\n\nIn case where I do not have moderators or I'm interested only in between-papers variability, aggregating is totally fine.\n\nWe can expand this even to situations with more nesting level, outcomes nested within experiments nested within papers. If we are not interested in the effect sizes level (i.e., outcome level) aggregating is fine.\n\n# Example\n\nHere I simulate a dataset with $K$ papers. Each papers can have a maximum of $J$ experiments and each experiments can have 1 (e.g., ACC or RT) or 2 (e.g., ACC and RT) outcomes colected on the same pool of subjects.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(metafor)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: Matrix\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: metadat\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: numDeriv\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nLoading the 'metafor' package (version 4.0-0). For an\nintroduction to the package please type: help(metafor)\n```\n\n\n:::\n\n```{.r .cell-code}\nseqw <- function(x){\n  unlist(sapply(x, function(i) 1:i))\n}\nset.seed(2023)\n```\n:::\n\n\nWe start by simulating the data structure. The number of experiments and outcomes is random:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nK <- 100 # number of papers\nJ <- sample(1:3, K, replace = TRUE) # number of studies, within each paper\nZ <- sample(1:2, sum(J), replace = TRUE) # number of outcomes per study/paper\n\ndat <- data.frame(paper = rep(rep(1:K, J), Z), \n                  exp = rep(seqw(J), Z), \n                  effect = seqw(Z))\n\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  paper exp effect\n1     1   1      1\n2     1   1      2\n3     2   1      1\n4     2   1      2\n5     2   2      1\n6     2   3      1\n```\n\n\n:::\n:::\n\n\nThen we set our simulation parameters. We have 3 heterogeneity components: $\\tau^2$, $\\omega^2$ and $\\zeta^2$. I simulate a meta-regression model because I simulate a difference between the effect on the two outcomes but I'm not interested in fitting a meta-regression (just a shortcut to simulate the difference).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# residual variance components\ntau2 <- 0.3\nomega2 <- 0.1\nzeta2 <- 0.1\n\nb0 <- 0.1\nb1 <- 0.1\n\n# random effects\nb0_i <- rnorm(K, 0, sqrt(tau2))\nb0_ij <- rnorm(sum(J), 0, sqrt(omega2))\nb0_ijz <- rnorm(nrow(dat), 0, sqrt(zeta2))\n\n# add to dataframe\ndat$b0_i <- b0_i[dat$paper]\ndat$b0_ij <- rep(b0_ij, Z)\ndat$b0_ijz <- b0_ijz\ndat$vi <- runif(nrow(dat), 0.05, 0.1) # random sampling variances\n\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  paper exp effect        b0_i       b0_ij      b0_ijz         vi\n1     1   1      1 -0.04382947 -0.23146442 -0.31300488 0.08194773\n2     1   1      2 -0.04382947 -0.23146442  0.18361480 0.05893909\n3     2   1      1  0.15294661  0.09919803  0.45521629 0.06651081\n4     2   1      2  0.15294661  0.09919803  0.01169994 0.06953170\n5     2   2      1  0.15294661  0.32233407  0.20481287 0.09750496\n6     2   3      1  0.15294661  0.15360518  0.04071347 0.06072859\n```\n\n\n:::\n:::\n\n\nNow the crucial part, we need to create the block-variance-covariance matrix of the sampling errors. Crucially, sampling errors are correlated **ONLY** when we have multiple **outcomes** because experiments within the same paper have different subjects. The matrix should reflect this feature.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create block-matrix\nV <- vcalc(vi, \n           cluster = paper, # 1st level cluster\n           subgroup = exp,  # independent experiments\n           obs = effect, # correlated effects\n           rho = 0.7, # correlation\n           data = dat)\n\n# splitting the matrix just for reference\nVb <- blsplit(V, dat$paper, fun = round, 3)\n```\n:::\n\n\nFor example, the second paper has 3 experiments. The first experiment has two outcomes while the second and the third have only one outcome.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat[dat$paper == 2, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  paper exp effect      b0_i      b0_ij     b0_ijz         vi\n3     2   1      1 0.1529466 0.09919803 0.45521629 0.06651081\n4     2   1      2 0.1529466 0.09919803 0.01169994 0.06953170\n5     2   2      1 0.1529466 0.32233407 0.20481287 0.09750496\n6     2   3      1 0.1529466 0.15360518 0.04071347 0.06072859\n```\n\n\n:::\n:::\n\n\nThus sampling errors are correlated only for experiment 1, let's see the matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nVb[[2]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      [,1]  [,2]  [,3]  [,4]\n[1,] 0.067 0.048 0.000 0.000\n[2,] 0.048 0.070 0.000 0.000\n[3,] 0.000 0.000 0.098 0.000\n[4,] 0.000 0.000 0.000 0.061\n```\n\n\n:::\n:::\n\n\nNow we can use `V` to simulate the sampling errors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# sampling errors\ne_ij <- MASS::mvrnorm(1, mu = rep(0, nrow(V)), Sigma = V)\n```\n:::\n\n\nFinally we can simulate the different effect size for each outcome:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# moderator (ACC, RT)\ndat$x <- ifelse(dat$effect == 1, 1, 0)\n\n# observed effect size\ndat$yi <- with(dat, (b0 + b0_i + b0_ij + b0_ijz) + b1*x + e_ij)\ndat$x <- factor(dat$x)\ndat$exp <- factor(dat$exp)\n\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  paper exp effect        b0_i       b0_ij      b0_ijz         vi x         yi\n1     1   1      1 -0.04382947 -0.23146442 -0.31300488 0.08194773 1 -0.5126605\n2     1   1      2 -0.04382947 -0.23146442  0.18361480 0.05893909 0 -0.1950280\n3     2   1      1  0.15294661  0.09919803  0.45521629 0.06651081 1  0.9493747\n4     2   1      2  0.15294661  0.09919803  0.01169994 0.06953170 0  0.1391810\n5     2   2      1  0.15294661  0.32233407  0.20481287 0.09750496 1  1.2265437\n6     2   3      1  0.15294661  0.15360518  0.04071347 0.06072859 1  0.6342383\n```\n\n\n:::\n:::\n\n\n## Model without aggregation\n\nTo compare the model with and without aggregation, the trick is fitting a model without the lowest nesting level in the random effect structure. Normally, the simulated dataset above should be modeled (for the random part) as `1|paper/exp/effect`. Here we drop the `effect` term:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit0 <- rma.mv(yi, V, random = ~1|paper/exp, data = dat, sparse = TRUE)\n\nsummary(fit0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 293; method: REML)\n\n   logLik   Deviance        AIC        BIC       AICc   \n-463.2780   926.5559   932.5559   943.5862   932.6393   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed     factor \nsigma^2.1  0.3506  0.5921    100     no      paper \nsigma^2.2  0.1651  0.4063    193     no  paper/exp \n\nTest for Heterogeneity:\nQ(df = 292) = 2486.0170, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval    ci.lb   ci.ub    \n  0.0010  0.0699  0.0147  0.9883  -0.1360  0.1381    \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nUsing the `V` matrix we are fixing the correlation between multiple outcomes (i.e., the lowest nesting level) to 0.7.\n\n## Model with aggregation\n\nTo aggregate we use the Borenstein method implemented in the `aggregate` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# with aggregation\ndat <- escalc(yi = yi, vi = vi, data = dat)\ndatl <- split(dat, dat$paper)\ndatl <- lapply(datl, function(x) aggregate(x, cluster = exp, rho = 0.7))\ndatagg <- do.call(rbind, datl)\n\nhead(datagg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n    paper exp effect        b0_i       b0_ij      b0_ijz     vi x      yi \n1       1   1    1.5 -0.04382947 -0.23146442 -0.06469504 0.0565 1 -0.2700 \n2.1     2   1    1.5  0.15294661  0.09919803  0.23345811 0.0578 1  0.5742 \n2.2     2   2    1.0  0.15294661  0.32233407  0.20481287 0.0975 1  1.2265 \n2.3     2   3    1.0  0.15294661  0.15360518  0.04071347 0.0607 1  0.6342 \n3       3   1    1.0 -0.00408931  0.23980867 -0.20986505 0.0874 1  0.0607 \n4.1     4   1    1.5  0.25987891 -0.17661214  0.19485017 0.0701 1  0.4567 \n```\n\n\n:::\n:::\n\n\nThen we fit the same model but without using `V` (sampling errors are never correlated now) instead we use `v` and the same random structure:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- rma.mv(yi, vi, random = ~1|paper/exp, data = datagg, sparse = TRUE)\n\nsummary(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 193; method: REML)\n\n   logLik   Deviance        AIC        BIC       AICc   \n-196.5763   393.1527   399.1527   408.9251   399.2803   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed     factor \nsigma^2.1  0.3506  0.5921    100     no      paper \nsigma^2.2  0.1651  0.4063    193     no  paper/exp \n\nTest for Heterogeneity:\nQ(df = 192) = 1825.2162, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval    ci.lb   ci.ub    \n  0.0010  0.0699  0.0147  0.9883  -0.1360  0.1381    \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nThe two models are exactly the same.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}