{
  "hash": "fb083c6245f82686817045caf9e82414",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Sensitivity Analysis\"\ndate: \"2024-01-28\"\ncategories: [linear-regression]\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Packages\n\nlibrary(tidyverse)\nlibrary(pwr)\nlibrary(BayesFactor)\n\n# Seed for simulation\n\nset.seed(2021)\n```\n:::\n\n\n# General idea\n\nThe **sensitivity analysis** is a way to estimate the effect size that a given experiment can reach with a certain sample size, desired power and alpha level [@perugini2018practical].\n\nThe power analysis is usually considered a procedure that estimate a single number (i.e., the sample size) required for a given statistical analysis to reach a certain power level. Is better to consider the power level as a **function** with *fixed* and *free* parameters.\n\nIn the case of the *a priori* power analysis, we fix the power level (e.g., $1 - \\beta = 0.80$) the alpha level (e.g., $\\alpha = 0.05$\") and the hypothetical effect size (e.g, $d = 0.3$). Then we simulate or derive analytically the minimum sample size required for reaching the target power level, given the effect size.\n\nA more appropriate approach is to consider the sample size a free parameter and calculate the power level for a range of sample size, obtaining the **power curve**. This is very easy using the `pwr` package. We assume:\n\n- $1-\\beta = 0.8$\n- $\\alpha = 0.05$\n- $d = 0.3$\n- an **independent sample t-test situation**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npower_analysis <- pwr::pwr.t.test(\n  d = 0.3, \n  power = 0.8,\n  sig.level = 0.05\n)\npower_analysis\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two-sample t test power calculation \n\n              n = 175.3847\n              d = 0.3\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n\n\n:::\n:::\n\n\nFrom the output we need 175.3846666 subjects per group for reaching the desired power level. As said before a better approach is analyzing the entire power curve. We can simply plot the `power_analysis` object:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(power_analysis)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/pwr-curve-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\n# Power by simulation\n\nThe previous example is based on the analytically power computation that is possible for simple statistical test. A more general approach is the **power analysis by simulation**.\n\nIf we know the statistical assumptions of our analysis we can simulate data accordingly several times (e.g., 10000 simulations) and simply count the number of **p values** below the alpha level. This is a little bit too much for a simple t-test but can be really insightful.\n\nWe need to simulate two groups sampled from two populations with different mean (our effect size) and with the same standard deviation. We can simulate directly on the `cohen's d` scale setting the *standard deviation* to 1 and the mean difference to the desired `d` level.\n\nFor obtaining the power curve we need a range of sample size from 10 to 200 for example.\n\nThere are multiple ways to approach a simulation. Here I declare my parameters and create a grid of values using the `tidyr::expand_grid()` function to create all combinations. The I simply need to loop for each row, generate data using `rnorm`, calculate the `t-test` and then count how many `p-values` are below the alpha level.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmp0 <- 0\nmp1 <- 0.3\nsd_p <- 1\n# d = mp1 - mp0 / sigma = (0.3 - 0) / 1 = 0.3\nsample_size <- seq(10, 200, 30)\nnsim <- 1000\nalpha_level <- 0.05\n\nsim <- expand_grid(\n  mp0,\n  mp1,\n  sd_p,\n  sample_size,\n  nsim = 1:nsim,\n  p_value = 0\n)\n\n# Using the for approach for clarity, *apply or map is better\n\nfor(i in 1:nrow(sim)){\n  g0 <- rnorm(sim$sample_size[i], sim$mp0[i], sim$sd_p[i])\n  g1 <- rnorm(sim$sample_size[i], sim$mp1[i], sim$sd_p[i])\n  sim[i, \"p_value\"] <- t.test(g0, g1)$p.value\n}\n\nsim %>% \n  group_by(sample_size, mp1) %>% \n  summarise(power = mean(p_value < alpha_level)) %>% \n  ggplot(aes(x = sample_size, y = power)) +\n  geom_point(size = 3) +\n  geom_line() +\n  ggtitle(paste(\"Effect size = \", sim$mp1[1]))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/power-simulation-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\nThe result is very similar to the `pwr` result. Increasing the number of simulation will stabilize the results. As said before, using this approach for a `t-test` is not convenient but with the same code and idea we can simulate an unequal variance situation or having different sample size per group.\n\n# Sensitivity Analysis\n\nUsing the same approach as before, we can perform a sensivity analysis simply changing our free parameters in the previous simulation. The sensitivity analysis is usually performed with a given sample size and the the `free` parameter will be the effect size. We can use a range from 0 (the null effect) to 1 and fixing a sample size of 50 subjects per group.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmp0 <- 0\nmp1 <- seq(0, 1, 0.2)\nsd_p <- 1\nsample_size <- 50\nnsim <- 1000\nalpha_level <- 0.05\n\nsim <- expand_grid(\n  mp0,\n  mp1,\n  sd_p,\n  sample_size,\n  nsim = 1:nsim,\n  p_value = 0\n)\n\n# Using the for approach for clarity, *apply or map is better\n\nfor(i in 1:nrow(sim)){\n  g0 <- rnorm(sim$sample_size[i], sim$mp0[i], sim$sd_p[i])\n  g1 <- rnorm(sim$sample_size[i], sim$mp1[i], sim$sd_p[i])\n  sim[i, \"p_value\"] <- t.test(g0, g1)$p.value\n}\n\nsim %>% \n  group_by(mp1, sample_size) %>% \n  summarise(power = mean(p_value < alpha_level)) %>% \n  ggplot(aes(x = mp1, y = power)) +\n  geom_point(size = 3) +\n  geom_line() +\n  geom_hline(yintercept = 0.8, linetype = \"dashed\", size = 1, col = \"red\") +\n  ggtitle(paste(\"Sample size = \", sim$sample_size[1]))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/sens-simulation-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\nWith the simulation approach we simply have to change our grid of values and calculate the power grouping for effect size instead of sample size. Here we understand that with a sample size of 50 we can detect with 80% power an effect size of ~0.6. If the true effect size is lower than the maximum detectable effect size, we are using an under-powered design.\n\n# Script\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## -----------------------------------------------------------------------------\n## Script: Sensitivity analysis\n##\n## Author: Filippo Gambarota\n## -----------------------------------------------------------------------------\n\n# Packages ----------------------------------------------------------------\n\nlibrary(tidyverse)\nlibrary(furrr)\n\n# Environment -------------------------------------------------------------\n\nset.seed(2021)\n\n# Functions ---------------------------------------------------------------\n\n# Find the closest target from a vector\n\nfind_closest_n <- function(vector, target){\n  index <- which.min(abs(vector - target))\n  out <- vector[index]\n  return(out)\n}\n\n# Return the minimun effect size given a sample size and the power level\n\nmin_effect <- function(data, sample_size, power_level){\n  ns <- find_closest_n(unique(data$sample_size), sample_size)\n  min(data$effect_size[data$sample_size == ns & data$power >= power_level])\n}\n\n# Calculate power\n\ncompute_power <- function(data, alpha){\n  data %>% \n    group_by(sample_size, effect_size) %>% \n    summarise(power = mean(ifelse(p_value < alpha, 1, 0)))\n}\n\n# Plot the contour\n\npower_contour <- function(data){\n  data %>% \n    ggplot(aes(x = sample_size, y = effect_size, z = power)) +\n    geom_contour_filled(breaks = seq(0,1,0.1)) +\n    coord_cartesian() +\n    cowplot::theme_minimal_grid()\n}\n\n# Plot the power curve\n\npower_curve <- function(data, n){\n  ns <- find_closest_n(unique(data$sample_size), n)\n  data %>% \n    filter(sample_size == ns) %>% \n    ggplot(aes(x = effect_size, y = power)) +\n    geom_point() +\n    geom_line() +\n    cowplot::theme_minimal_grid() +\n    ggtitle(paste(\"Sample size =\", ns))\n}\n\n# Setup simulation --------------------------------------------------------\n\nsample_size <- seq(10, 500, 50)\neffect_size <- seq(0, 1, 0.1)\nnsim <- 1000\n\nsim <- expand_grid(\n  sample_size,\n  effect_size,\n  sim = 1:nsim\n)\n\n# Test --------------------------------------------------------------------\n\nplan(multisession(workers = 4))\n\nsim$p_value <- furrr::future_map2_dbl(sim$sample_size, sim$effect_size, function(x, y){\n  g0 <- rnorm(x, 0, 1)\n  g1 <- rnorm(x, y, 1)\n  t.test(g0, g1)$p.value\n}, .options = furrr_options(seed = TRUE))\n\n# Computing power\n\nsim_power <- compute_power(sim, alpha = 0.05)\n\n# Plots -------------------------------------------------------------------\n\n# Contour plot\n\npower_contour(sim_power)\n\n# Power curve\n\npower_curve(sim_power, 200)\n```\n:::\n\n\n\n# Bayesian\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsim <- expand_grid(\n  mp0,\n  mp1,\n  sd_p,\n  sample_size,\n  nsim = 1:nsim,\n  p_value = 0,\n  bf = 0\n)\n\n# Using the for approach for clarity, *apply or map is better\n\nfor(i in 1:nrow(sim)){\n  g0 <- rnorm(sim$sample_size[i], sim$mp0[i], sim$sd_p[i])\n  g1 <- rnorm(sim$sample_size[i], sim$mp1[i], sim$sd_p[i])\n  sim[i, \"p_value\"] <- t.test(g0, g1)$p.value\n  sim[i, \"bf\"] <- extractBF(ttestBF(g0,g1))$bf\n}\n\nsim %>% \n  group_by(mp1, sample_size) %>% \n  summarise(power = mean(p_value < alpha_level),\n            bf = mean(log(bf))) %>% \n  pivot_longer(c(power, bf), names_to = \"metric\", values_to = \".value\") %>% \n  ggplot(aes(x = mp1, y = .value)) +\n  facet_wrap(~metric, scales = \"free\") +\n  geom_point(size = 3) +\n  geom_line() +\n  ggtitle(paste(\"Sample size = \", sim$sample_size[1]))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\n# Session info\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.2.3 (2023-03-15)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS 14.4.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] BayesFactor_0.9.12-4.7 Matrix_1.5-3           coda_0.19-4           \n [4] pwr_1.3-0              lubridate_1.9.2        forcats_1.0.0         \n [7] stringr_1.5.0          dplyr_1.1.2            purrr_1.0.1           \n[10] readr_2.1.4            tidyr_1.3.0            tibble_3.2.1          \n[13] ggplot2_3.5.0          tidyverse_2.0.0       \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.10        compiler_4.2.3     pillar_1.9.0       tools_4.2.3       \n [5] digest_0.6.31      lattice_0.20-45    timechange_0.2.0   jsonlite_1.8.4    \n [9] evaluate_0.20      lifecycle_1.0.3    gtable_0.3.3       pkgconfig_2.0.3   \n[13] rlang_1.1.0        cli_3.6.1          rstudioapi_0.14    parallel_4.2.3    \n[17] yaml_2.3.7         mvtnorm_1.1-3      xfun_0.39          fastmap_1.1.1     \n[21] withr_2.5.0        knitr_1.42         MatrixModels_0.5-1 generics_0.1.3    \n[25] vctrs_0.6.2        htmlwidgets_1.6.2  hms_1.1.3          grid_4.2.3        \n[29] tidyselect_1.2.0   glue_1.6.2         R6_2.5.1           pbapply_1.7-0     \n[33] fansi_1.0.4        rmarkdown_2.21     farver_2.1.1       tzdb_0.4.0        \n[37] magrittr_2.0.3     codetools_0.2-19   scales_1.3.0       htmltools_0.5.5   \n[41] colorspace_2.1-0   labeling_0.4.2     utf8_1.2.3         stringi_1.7.12    \n[45] munsell_0.5.0     \n```\n\n\n:::\n:::\n\n\n# References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}